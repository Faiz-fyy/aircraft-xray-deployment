{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da50ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aircraft X-Ray CNN Production Deployment\n",
    "=======================================\n",
    "Production web deployment of ResNet50 CNN for automated aircraft X-ray water ingression detection.\n",
    "Target: 92.9% accuracy achieved with PyTorch + FastAPI for live web application deployment.\n",
    "Dataset: 138 X-ray images with mobile-responsive interface and safety-critical confidence scoring\n",
    "Method: TensorFlowâ†’PyTorch migration with FastAPI backend and JavaScript frontend\n",
    "Key Features: Three-tier confidence framework, mobile camera integration, Hugging Face Spaces deployment\n",
    "Technical Achievement: Complete ML lifecycle from research model to accessible production application\n",
    "Deployment: Live web app with drag-and-drop ROI selection and real-time prediction capabilities\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76710b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reproducibility and Device configuration\n",
    "# Random seeds for reproducibility\n",
    "def set_random_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seeds(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Configuration\n",
    "DATA_DIR = r\"[FILE PATH HERE]\"  # Folder path here\n",
    "BATCH_SIZE = 8\n",
    "IMG_HEIGHT = 350\n",
    "IMG_WIDTH = 512\n",
    "\n",
    "# Custom Dataset Class\n",
    "class WaterDetectionDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, split='train', val_split=0.2, seed=42):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.seed = seed\n",
    "        \n",
    "        # Get all image paths and labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Assuming folder structure: DATA_DIR/class1/, DATA_DIR/class2/\n",
    "        class_folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]\n",
    "        class_folders.sort()  # Ensure consistent ordering\n",
    "        \n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_folders)}\n",
    "        print(f\"Class indices: {self.class_to_idx}\")\n",
    "        \n",
    "        for class_name in class_folders:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            image_files = glob.glob(os.path.join(class_dir, \"*\"))\n",
    "            image_files = [f for f in image_files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "            \n",
    "            for img_path in image_files:\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(self.class_to_idx[class_name])\n",
    "        \n",
    "        # Split data\n",
    "        np.random.seed(seed)\n",
    "        indices = np.random.permutation(len(self.image_paths))\n",
    "        split_idx = int(len(indices) * (1 - val_split))\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.indices = indices[:split_idx]\n",
    "        else:\n",
    "            self.indices = indices[split_idx:]\n",
    "        \n",
    "        print(f\"{split.capitalize()} samples: {len(self.indices)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.indices[idx]\n",
    "        image_path = self.image_paths[actual_idx]\n",
    "        label = self.labels[actual_idx]\n",
    "        \n",
    "        # Load image as grayscale\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae166e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=0, shear=0.1, scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    # Convert grayscale to RGB for ResNet\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = WaterDetectionDataset(DATA_DIR, transform=train_transforms, split='train')\n",
    "val_dataset = WaterDetectionDataset(DATA_DIR, transform=val_transforms, split='val')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8bb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Definition\n",
    "class ResNetWaterDetector(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(ResNetWaterDetector, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Freeze early layers (keep last 20 trainable)\n",
    "        layers_to_freeze = list(self.backbone.children())[:-2]  # All except avgpool and fc\n",
    "        for layer_group in layers_to_freeze[:-3]:  # Freeze all but last few layer groups\n",
    "            for param in layer_group.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Remove the final classification layer\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])\n",
    "        \n",
    "        # Custom classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        output = self.classifier(features)\n",
    "        return output.squeeze()\n",
    "\n",
    "# Create model\n",
    "model = ResNetWaterDetector().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3, min_lr=1e-7)\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Functions\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = accuracy_score(all_labels, all_predictions)\n",
    "    epoch_precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "    epoch_recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_precision, epoch_recall, all_labels, all_predictions, all_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15, patience=6):\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_precision': [], 'val_recall': []}\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc, val_precision, val_recall, _, _, _ = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['val_recall'].append(val_recall)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"New best validation accuracy: {best_val_acc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience: {patience_counter}/{patience}\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"Loaded best model with validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804846e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Evaluation\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    val_loss, val_acc, val_precision, val_recall, y_true, y_pred, y_prob = validate_epoch(model, dataloader, criterion, device)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Classification report\n",
    "    target_names = ['Nil', 'Water']\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    \n",
    "    print(f\"Accuracy:  {val_acc:.3f}\")\n",
    "    print(f\"Precision: {val_precision:.3f}\")\n",
    "    print(f\"Recall:    {val_recall:.3f}\")\n",
    "    print(f\"F1 Score:  {f1:.3f}\")\n",
    "    print(f\"ROC AUC:   {auc:.3f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Nil', 'Water'], yticklabels=['Nil', 'Water'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    return val_acc, val_precision, val_recall, f1, auc\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "accuracy, precision, recall, f1, auc = evaluate_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training History Visualization\n",
    "def plot_training_history(history):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history['train_acc'], label='Training Accuracy')\n",
    "    axes[0, 0].plot(history['val_acc'], label='Validation Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history['train_loss'], label='Training Loss')\n",
    "    axes[0, 1].plot(history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Precision\n",
    "    axes[1, 0].plot(history['val_precision'], label='Validation Precision')\n",
    "    axes[1, 0].set_title('Model Precision')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 1].plot(history['val_recall'], label='Validation Recall')\n",
    "    axes[1, 1].set_title('Model Recall')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confidence Interpretation\n",
    "def interpret_prediction(confidence_score):\n",
    "    if confidence_score > 0.8:\n",
    "        return f\"HIGH CONFIDENCE: {confidence_score:.1%}\"\n",
    "    elif confidence_score > 0.6:\n",
    "        return f\"MEDIUM CONFIDENCE: {confidence_score:.1%}\"\n",
    "    else:\n",
    "        return f\"LOW CONFIDENCE: {confidence_score:.1%} - Manual review recommended\"\n",
    "\n",
    "def test_predictions(model, dataloader, device, num_samples=10):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            if len(results) >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            for j in range(images.size(0)):\n",
    "                if len(results) >= num_samples:\n",
    "                    break\n",
    "                    \n",
    "                confidence = outputs[j].item()\n",
    "                predicted_class = 1 if confidence > 0.5 else 0\n",
    "                true_label = 'Water' if labels[j].item() == 1 else 'Nil'\n",
    "                pred_label = 'Water' if predicted_class == 1 else 'Nil'\n",
    "                confidence_interp = interpret_prediction(confidence)\n",
    "                \n",
    "                results.append({'Batch': i, 'Sample': j, 'True_Label': true_label, 'Predicted_Label': pred_label, 'Confidence_Score': confidence, \n",
    "                                'Confidence_Interpretation': confidence_interp, 'Correct_Prediction': predicted_class == labels[j].item()})\n",
    "                \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "predictions_df = test_predictions(model, val_loader, device, 10)\n",
    "print(predictions_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single Image Prediction\n",
    "def test_single_image(image_path, model, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    original_image = image.copy()\n",
    "    \n",
    "    # Apply same transforms as validation (without augmentation)\n",
    "    transform = transforms.Compose([transforms.Resize((IMG_HEIGHT, IMG_WIDTH)), transforms.ToTensor(), transforms.Lambda(lambda x: x.repeat(3, 1, 1)), \n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image_tensor).item()\n",
    "    \n",
    "    predicted_class = 'Water' if prediction > 0.5 else 'Nil'\n",
    "    confidence_interp = interpret_prediction(prediction)\n",
    "    \n",
    "    # Display results\n",
    "    display_img = original_image.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(display_img, cmap='gray')\n",
    "    plt.title(f'Test: {os.path.basename(image_path)}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.text(0.1, 0.7, f\"Prediction: {predicted_class}\", fontsize=14, weight='bold')\n",
    "    plt.text(0.1, 0.5, f\"Confidence: {prediction:.3f}\", fontsize=12)\n",
    "    plt.text(0.1, 0.3, confidence_interp, fontsize=10)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.axis('off')\n",
    "    plt.title('Results')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"File: {os.path.basename(image_path)}\")\n",
    "    print(f\"Prediction: {predicted_class}\")\n",
    "    print(f\"Confidence: {prediction:.6f}\")\n",
    "    print(f\"Interpretation: {confidence_interp}\")\n",
    "    \n",
    "    return prediction, predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8bc904",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test single image (uncomment below)\n",
    "# test_single_image(r\"[FILE PATH HERE]\" , model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ba133",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Model\n",
    "# torch.save(model.state_dict(), 'Aircraft_Flap_Water_Detection_PyTorch.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
